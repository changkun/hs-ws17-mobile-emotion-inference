\section{Data Sources}\label{sec:source}

- \cite{Tao2005} gives image for different information and different related sensing.
- \cite{Poria2017} gives multimodal considerations image. 90\% literature consider visual, audio and text information as multimodal affect analysis

\subsection{Camera}\label{subsec:vision}
We emphasis vision sensors in the first place since face and facial expressions are undoubtedly one of the most important nonverbal channels used by the human being to convey internal emotion. This part mainly discusses vision sensors, which includes RGB camera and depth camera, and illustrates how vision sensor can be used for affective emotion inferring.

Pure RGB cameras has been widely used in commercial smartphone as image sensor. 
For the camera with depth informations on mobile (recently introduced TrueDepth Camera in iPhone X \footnote{\url{https://www.apple.com/iphone-x/\#truedepth-camera}}) combines infrared camera, flood illuminator, proximity sensor, ambient light sensor, front facing camera and dot projector to provide depth images of facial information of a user.

\cite{}


\subsection{Touch Screen}\label{subsec:touch}
Capacitive touch screen provides touch position, touch pressure, touch angle through time within a specific application context
\cite{Hertenstein2009, Gao2012, Shah2015, bhattacharya2017predictive}
% 这一部分主要讨论如何使用触摸传感器，可以触摸传感器的不同类型，研究项目中都是怎样使用触摸传感器的特征的？
% 几个可能的方面
% 1. 有文章显示 touch 行为可以进行情感交流 \cite{Hertenstein2009}
% 2. 在特定的应用情境下，有文章显示 touxh 行为可以推导当前的用户情感..cite???  这篇文章则提出了
% 3. 有文章首先总结了 haptic-based affect detection remains an understudy topic; \cite{Bhattacharya2017}
% 4. 既然触摸行为在表达情感上具有重要的指示，那么反过来如何用通过触摸来表达情感\cite{Lentini2017}\cite{Mazzoni2016}
This part mainly discusses touch sensors, which includes capacitive touch screen and 3D touch screen.
And also explain why touch sensor can be used for affective computing (they are applicable
because of specific application context), mainly cite these papers: ...

\subsection{Motion Sensors}\label{subsec:motion}
Motion sensors typically combines gyroscope and accelerometer, with this combination they can also provide device attitude
This part illustrate \cite{Rana, Mottelson2016, Bailenson2007}


\begin{itemize}
    \item \cite{Mottelson2016}: studied the implications of
    human affect on general purpose touch-based mobile interaction and showed that it is possible to detect mobile users’ positive and neutral affective states.
\end{itemize}

Motion sensors become important because it could tells us what is user's body language.

\subsection{Microphone}\label{subsec:audio}
Audio sensor usually refers to built-in microphones, it collects voice information from current environments, which can infers user emotions based on their speech contents

Audio sensors mainly infers to input and output microphones. This leans two part of affective computing:

First is inferring emotions from user speech. 
This task can also split as two part of inferring task, and one is directly infer from voice;
another is recognize speech text from user, then understanding or inferring from text.

Second is output a emotional speech from machines.

\subsection{GPS}\label{subsec:gps}
GPS sensors provides geographical information of a user. With Location Based Services, user emotion can be inferred by their location

\subsection{Application Context}\label{subsec:ui}