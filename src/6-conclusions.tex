\section{Conclusions}
\label{sec:conclusion}

In this paper, we investigated the recent advances in mobile affective computing related to human-computer interaction projects and inference techniques.

Section~\ref{sec:source} addresses different data sources in various mobile commodity sensors for emotion inference in previous studies. These include camera, touch screen, motion sensors, microphone, GPS, and application context. 

Next, in the Section~\ref{sec:methods}, 
we first carried out the review of emotion inference methods based on different type of data source, and compared the tested methods and inference models from previous researchers. In these comparisons, we first reviewed various models for user emotion inference, researchers usually transfers emotion inference problem into a classification problem. As a classification problem, most researchers consider user emotions can be inferred to three different states (Happy, Unhappy, Neutral). In each subsection, we highlighted the most useful methods for different type of emotion inference that concluded by the most recent research papers, such as CNN as the best way of vision type, RNN as the best way of auditory type, and handcrafted feature with SVM as the best way of interaction details. At the end of this section, we considered the combinations of these types of data. According to our investigation, the most commonly used data type are suggested to \emph{vision and audio} data in mobile affective computing; However, the combination of \emph{vision, audio, interaction details, and context for aspects fusion are unmined open topics}.

In Section~\ref{sec:applications}, we survey two novel applications in human-computer interaction related projects driven by emotion inference. Voice user interfaces consider user emotion as inputs and suggest to please users by adjusting system voice tone; Adaptive graphics user interfaces then considers emotion state as the context of UI theme.

Despite we researched the scientific approaches of mobile emotion inference in human-computer interaction related topics, there still apparent challenges in this area. Section~\ref{sec:challenges} pointed out the current problems of this research area. The main challenges of this area are \emph{impermeable emotions} and \emph{continuous understanding}. Moreover, the generalisability of mobile affective computing applications are subject to certain limitations. For instance, most of \emph{inference models are context specific} and multimodal inference then \emph{requires large computation resources}.

Nowadays, new technologies and methods provide us new opportunities of affect emotion inference in an unobtrusive mobile device. Since the complexity of the interpretation of human behavior at a very deep level is tremendous and requires a highly interdisciplinary collaboration, we believe the true break-throughs application in this field can be established by precisely modeling and new sensing technologies in the future.