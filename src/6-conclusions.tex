\section{Conclusions}
\label{sec:conclusion}

In this paper, we investigated the recent advances in mobile affective computing related to human-computer interaction projects and inferring techniques.

Section~\ref{sec:source} addresses different data sources in various mobile commodity sensors for emotion inferring in previous studies. These include camera, touch screen, motion sensors, microphone, GPS, and application context. 

Next, in the Section~\ref{sec:methods}, 
we first carried out the review of emotion inferring methods based on different type of data source, and compared the tested methods and inferring models from previous researchers. In these comparisons, we first reviewed various models for user emotion inferring, researchers usually transfers emotion inferring problem into a classification problem. As a classification problem, most researchers consider user emotions can be inferred to three different states (Happy, Unhappy, Neutral). In each subsection, we highlighted the most useful methods for different type of emotion inferring that concluded by the most recent research papers, such as CNN as the best way of vision type, RNN as the best way of auditory type, and handcrafted feature with SVM as the best way of interaction details. At the end of this section, we considered the combinations of these types of data. According to our investigation, the most commonly used data type are suggested to \emph{vision and audio} data in mobile affective computing; However, the combination of \emph{vision, audio, interaction details, and context four aspects fusion are unmined open topics}.

In Section~\ref{sec:applications}, we survey two novel applications in human-computer interaction related projects driven by emotion inferring. Voice user interfaces consider user emotion as inputs and suggest to please users by adjusting system voice tone; Adaptive graphics user interfaces then considers emotion state as the context of UI theme.

Despite we researched the scientific approaches of mobile emotion inferring in human-computer interaction related topics, there still apparent challenges in this area. Section~\ref{sec:challenges} pointed out the current problems of this research area. The main challenges of this area are \emph{impermeable emotions} and \emph{continuous understanding}. Moreover, the generalisability of mobile affective computing applications are subject to certain limitations. For instance, most of \emph{inferring models are context specific} and multimodal inferring then \emph{requires large computation resources}.

Nowadays, new technologies and methods provide us new opportunities of affect emotion inferring in an unobtrusive mobile device. Since the complexity of the interpretation of human behavior at a very deep level is tremendous and requires a highly interdisciplinary collaboration, we believe the true break-throughs application in this field can be established by precisely modeling and new sensing technologies in the future.